{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459eba8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f8e6df2",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb99b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a820199",
   "metadata": {},
   "source": [
    "# Repro & CUDA perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473bb191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU | CUDA: 12.1\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True   # speed\n",
    "torch.backends.cudnn.deterministic = False  # ok avec benchmark\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} | CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720277a3",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619b6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.75, 1.0)),  # + robuste que simple Resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),  # éval stable\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f98ee2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9ced8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 11 -> ['bread', 'dairy', 'dessert', 'egg', 'fried']...\n"
     ]
    }
   ],
   "source": [
    "# ====== Dataset + split (deux ImageFolder séparés) ======\n",
    "root = \"dataset/train\"\n",
    "full_for_split = datasets.ImageFolder(root)  # juste pour les indices\n",
    "num_classes = len(full_for_split.classes)\n",
    "print(f\"Classes: {num_classes} -> {full_for_split.classes[:5]}{'...' if num_classes>5 else ''}\")\n",
    "\n",
    "train_size = int(0.9 * len(full_for_split))\n",
    "val_size = len(full_for_split) - train_size\n",
    "gen = torch.Generator().manual_seed(SEED)\n",
    "train_subset, val_subset = random_split(full_for_split, [train_size, val_size], generator=gen)\n",
    "\n",
    "# Crée DEUX datasets indépendants (même fichiers, transforms différents)\n",
    "train_dataset = datasets.ImageFolder(root, transform=transform_train)\n",
    "val_dataset   = datasets.ImageFolder(root, transform=transform_val)\n",
    "\n",
    "# Applique indices du split\n",
    "train_dataset = Subset(train_dataset, train_subset.indices)\n",
    "val_dataset   = Subset(val_dataset,   val_subset.indices)\n",
    "\n",
    "# ====== DataLoaders rapides ======\n",
    "num_workers = min(8, os.cpu_count() or 2)\n",
    "pin = device == \"cuda\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=pin,\n",
    "                          persistent_workers=(num_workers>0), prefetch_factor=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=pin,\n",
    "                          persistent_workers=(num_workers>0), prefetch_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f36e4",
   "metadata": {},
   "source": [
    "# Entrainement + Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_519758/14675521.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
      "/tmp/ipykernel_519758/14675521.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
      "/tmp/ipykernel_519758/14675521.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 | train_loss=1.1044 | val_loss=0.8739 | val_acc=0.8564\n",
      "↑ Nouveau meilleur modèle (val_acc=0.8564)\n",
      "Epoch 02/20 | train_loss=0.8419 | val_loss=0.7440 | val_acc=0.9113\n",
      "↑ Nouveau meilleur modèle (val_acc=0.9113)\n",
      "Epoch 03/20 | train_loss=0.7699 | val_loss=0.7650 | val_acc=0.9015\n",
      "Epoch 04/20 | train_loss=0.7263 | val_loss=0.7471 | val_acc=0.9053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[1;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     42\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/miniconda3/envs/chess-engine/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chess-engine/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chess-engine/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ====== Modèle ======\n",
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "model = models.efficientnet_b0(weights=weights)\n",
    "in_feats = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_feats, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
    "\n",
    "# ====== Critère / Optim / Scheduler ======\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)  # AdamW + LR un peu plus haut\n",
    "num_epochs = 20\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)  # aligne T_max sur n_epochs\n",
    "\n",
    "best_acc = 0.0\n",
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "# ====== Entraînement ======\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = total_loss / max(1, len(train_loader))\n",
    "\n",
    "    # ====== Validation ======\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / max(1, len(val_loader))\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # Logs\n",
    "    print(f\"Epoch {epoch:02d}/{num_epochs} | train_loss={avg_train_loss:.4f} \"\n",
    "          f\"| val_loss={avg_val_loss:.4f} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "    # Sauvegarde du meilleur\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"class_to_idx\": full_for_split.class_to_idx,\n",
    "            \"epoch\": epoch,\n",
    "            \"val_acc\": best_acc\n",
    "        }, \"best_efficientnet_b0.pth\")\n",
    "        print(f\"↑ Nouveau meilleur modèle (val_acc={best_acc:.4f})\")\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "print(f\"\\nEntraînement terminé. Meilleure val_acc : {best_acc:.4f}\")\n",
    "\n",
    "# ====== Courbes ======\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.title(\"Courbes de perte\")\n",
    "plt.xlabel(\"Époques\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_accuracies, label=\"Val Acc\")\n",
    "plt.title(\"Courbe de précision\")\n",
    "plt.xlabel(\"Époques\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecte des vraies/predites sur le set de validation\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=full_for_split.classes)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "disp.plot(ax=ax, xticks_rotation=90, cmap=\"Blues\", colorbar=False)\n",
    "plt.title(\"Matrice de confusion - Validation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad76c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(all_labels, all_preds, target_names=full_for_split.classes, output_dict=True)\n",
    "class_acc = {cls: report[cls][\"precision\"] for cls in report if cls in full_for_split.classes}\n",
    "\n",
    "# Tri des classes selon performance\n",
    "sorted_acc = sorted(class_acc.items(), key=lambda x: x[1])\n",
    "\n",
    "# Graphique clair\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh([x[0] for x in sorted_acc], [x[1] for x in sorted_acc])\n",
    "plt.xlabel(\"Précision par classe\")\n",
    "plt.ylabel(\"Classe\")\n",
    "plt.title(\"Performance du modèle par classe\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ed13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les noms des classes depuis ImageFolder\n",
    "class_names = full_for_split.classes\n",
    "\n",
    "# Compter les indices d'appartenance par classe\n",
    "train_counts = Counter([full_for_split.targets[i] for i in train_subset.indices])\n",
    "val_counts   = Counter([full_for_split.targets[i] for i in val_subset.indices])\n",
    "\n",
    "# Convertir en DataFrame pour lisibilité\n",
    "df_counts = pd.DataFrame({\n",
    "    \"Classe\": class_names,\n",
    "    \"Train\": [train_counts[i] for i in range(len(class_names))],\n",
    "    \"Validation\": [val_counts[i] for i in range(len(class_names))]\n",
    "})\n",
    "\n",
    "# Ajouter ratio train/val et total\n",
    "df_counts[\"Total\"] = df_counts[\"Train\"] + df_counts[\"Validation\"]\n",
    "df_counts[\"% Train\"] = (df_counts[\"Train\"] / df_counts[\"Total\"] * 100).round(1)\n",
    "df_counts[\"% Val\"] = (df_counts[\"Validation\"] / df_counts[\"Total\"] * 100).round(1)\n",
    "\n",
    "# Afficher\n",
    "print(df_counts.sort_values(\"Total\", ascending=False).to_string(index=False))\n",
    "\n",
    "# Visualisation rapide\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df_counts[\"Classe\"], df_counts[\"Train\"], label=\"Train\", alpha=0.7)\n",
    "plt.bar(df_counts[\"Classe\"], df_counts[\"Validation\"], label=\"Validation\", alpha=0.7)\n",
    "plt.title(\"Répartition des images par classe (Train vs Val)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess-engine",
   "language": "python",
   "name": "chess-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
